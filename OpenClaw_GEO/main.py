#!/usr/bin/env python3
import json
import os
import datetime
from datetime import timedelta
import sys
import time
import threading
import concurrent.futures
from api_client import GenericClient
from check_network import run_diagnostics
from analysis_engine import DeepInsightEngine

# Force unbuffered output for immediate feedback
sys.stdout.reconfigure(line_buffering=True)

# Global Lock for file writing to prevent race conditions
FILE_LOCK = threading.Lock()
PRINT_LOCK = threading.Lock()

import re
from collections import Counter

# Configuration Paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CONFIG_PATH = os.path.join(BASE_DIR, "config.json")
DATA_DIR = os.path.join(BASE_DIR, "data")

def load_config():
    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_config(config):
    with open(CONFIG_PATH, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)

def extract_competitors(answer):
    # Common Chinese tech companies/brands
    competitors = [
        "åä¸º", "Huawei", "å°ç±³", "Xiaomi", "é˜¿é‡Œ", "Alibaba", 
        "è…¾è®¯", "Tencent", "ç™¾åº¦", "Baidu", "å­—èŠ‚", "ByteDance",
        "äº¬ä¸œ", "JD", "æµ·å°”", "Haier", "ç¾çš„", "Midea",
        "æ¯”äºšè¿ª", "BYD", "å¤§ç–†", "DJI", "å®å¾·æ—¶ä»£", "CATL",
        "è”æƒ³", "Lenovo" # Include self for comparison
    ]
    found = []
    for c in competitors:
        if c in answer:
            # Normalize english names to Chinese for stats
            norm_name = c
            if c in ["Huawei"]: norm_name = "åä¸º"
            if c in ["Xiaomi"]: norm_name = "å°ç±³"
            if c in ["Alibaba"]: norm_name = "é˜¿é‡Œ"
            if c in ["Tencent"]: norm_name = "è…¾è®¯"
            if c in ["Baidu"]: norm_name = "ç™¾åº¦"
            if c in ["ByteDance"]: norm_name = "å­—èŠ‚"
            if c in ["JD"]: norm_name = "äº¬ä¸œ"
            if c in ["Haier"]: norm_name = "æµ·å°”"
            if c in ["Midea"]: norm_name = "ç¾çš„"
            if c in ["BYD"]: norm_name = "æ¯”äºšè¿ª"
            if c in ["DJI"]: norm_name = "å¤§ç–†"
            if c in ["CATL"]: norm_name = "å®å¾·æ—¶ä»£"
            if c in ["Lenovo"]: norm_name = "è”æƒ³"
            
            found.append(norm_name)
    return list(set(found))

def extract_sources_v2(answer):
    # æå–é“¾æ¥
    urls = re.findall(r'(https?://[^\s\)]+)', answer)
    
    # åª’ä½“åç§°æ˜ å°„
    media_map = {
        "36kr.com": "36æ°ª",
        "huxiu.com": "è™å—…",
        "sina.com": "æ–°æµª",
        "163.com": "ç½‘æ˜“",
        "sohu.com": "æœç‹",
        "caixin.com": "è´¢æ–°",
        "thepaper.cn": "æ¾æ¹ƒ",
        "jiemian.com": "ç•Œé¢",
        "zhihu.com": "çŸ¥ä¹",
        "wikipedia.org": "ç»´åŸºç™¾ç§‘"
    }
    
    sources = []
    for url in urls:
        media_name = "å…¶ä»–åª’ä½“"
        for domain, name in media_map.items():
            if domain in url:
                media_name = name
                break
        
        sources.append({
            "media": media_name,
            "url": url,
            "title": "ç›¸å…³æ–°é—»/æŠ¥å‘Š" 
        })
        
    media_keywords = ["36æ°ª", "è™å—…", "è´¢æ–°", "æ¾æ¹ƒ", "ç•Œé¢", "æ™šç‚¹", "çŸ¥ä¹", "ç»´åŸºç™¾ç§‘"]
    for m in media_keywords:
        if m in answer and not any(s['media'] == m for s in sources):
            sources.append({
                "media": m,
                "url": "å‚è€ƒå›ç­”æ–‡æœ¬",
                "title": f"å…³äº{m}çš„ç›¸å…³æŠ¥é“"
            })
            
    return sources

def get_beijing_time():
    """Get current time in Beijing (UTC+8)"""
    return datetime.datetime.utcnow() + timedelta(hours=8)

def save_result(intent_name, platform, question, result_obj, timestamp):
    # Use Beijing time for filename
    filename = f"{get_beijing_time().strftime('%Y%m%d')}_results.json"
    filepath = os.path.join(DATA_DIR, filename)
    
    answer = result_obj.get('content', '')
    reasoning = result_obj.get('reasoning', '')
    
    data = []
    if os.path.exists(filepath):
        with open(filepath, 'r', encoding='utf-8') as f:
            try:
                data = json.load(f)
            except:
                data = []
    
    # Check for Lenovo keywords in answer and reasoning
    is_mentioned = "è”æƒ³" in answer or "Lenovo" in answer or "lenovo" in answer
    mentioned_in_reasoning = "è”æƒ³" in reasoning or "Lenovo" in reasoning or "lenovo" in reasoning
    
    # Extract competitors and sources from BOTH answer and reasoning
    competitors_answer = extract_competitors(answer)
    competitors_reasoning = extract_competitors(reasoning)
    all_competitors = list(set(competitors_answer + competitors_reasoning))
    
    sources_answer = extract_sources_v2(answer)
    sources_reasoning = extract_sources_v2(reasoning)
    # Combine source lists carefully (dictionaries cannot be put into set directly)
    # Strategy: Use URL as unique key
    seen_urls = set()
    all_sources = []
    
    for s in sources_answer + sources_reasoning:
        # Use URL as key, but distinguish text-based references by media name
        key = s['url']
        if key == "å‚è€ƒå›ç­”æ–‡æœ¬":
            key = f"{key}_{s['media']}"
            
        if key not in seen_urls:
            all_sources.append(s)
            seen_urls.add(key)
    
    record = {
        "timestamp": timestamp,
        "intent": intent_name,
        "platform": platform,
        "question": question,
        "answer": answer,
        "reasoning": reasoning,
        "is_mentioned": is_mentioned,
        "mentioned_in_reasoning": mentioned_in_reasoning,
        "competitors": all_competitors,
        "sources": [s['media'] for s in all_sources], # Keep backward compatibility for 'sources' field which was list of strings
        "sources_v2": all_sources, # Add new structured field
        "sources_breakdown": {
            "answer": sources_answer,
            "reasoning": sources_reasoning
        },
        "answer_length": len(answer),
        "reasoning_length": len(reasoning)
    }
    
    data.append(record)
    
    with FILE_LOCK:
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    return is_mentioned, mentioned_in_reasoning

def generate_report():
    # Find all result files
    files = [f for f in os.listdir(DATA_DIR) if f.endswith('_results.json')]
    all_records = []
    for file in files:
        with open(os.path.join(DATA_DIR, file), 'r', encoding='utf-8') as f:
            all_records.extend(json.load(f))
            
    if not all_records:
        print("\nâš ï¸  æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œç›‘æµ‹ä»»åŠ¡ã€‚")
        return

    # Calculate stats
    total = len(all_records)
    mentioned = sum(1 for r in all_records if r['is_mentioned'])
    mentioned_cot = sum(1 for r in all_records if r.get('mentioned_in_reasoning') and not r['is_mentioned'])
    rate = (mentioned / total * 100) if total > 0 else 0
    
    print("\n" + "="*60)
    print(f"ğŸ“Š  GEO æ·±åº¦ç›‘æµ‹æŠ¥å‘Š (å…± {total} æ¡æ•°æ®)")
    print("="*60)
    print(f"âœ…  è”æƒ³æ€»ä½“æåŠç‡: {rate:.1f}% ({mentioned}/{total})")
    if mentioned_cot > 0:
        print(f"ğŸ¤”  (å¦æœ‰ {mentioned_cot} æ¬¡ä»…åœ¨æ¨ç†è¿‡ç¨‹ä¸­æåŠï¼Œæœªæœ€ç»ˆè¾“å‡º)")
    print("-" * 60)
    
    # Get all platforms from config to show full status
    config = load_config()
    all_providers = config.get('providers', {}).keys()
    
    # Existing data platforms
    data_platforms = set(r['platform'] for r in all_records)
    
    # Merge and sort
    platforms = sorted(list(set(list(all_providers) + list(data_platforms))))
    
    for p in platforms:
        p_recs = [r for r in all_records if r['platform'] == p]
        p_total = len(p_recs)
        
        print(f"\nğŸ“± å¹³å°: ã€{p}ã€‘")
        
        if p_total == 0:
             print("    âš ï¸  (æš‚æ— æ•°æ® - å¯èƒ½æœªé…ç½® Key æˆ–è¯·æ±‚å¤±è´¥)")
             print("-" * 30)
             continue
        
        p_ment = sum(1 for r in p_recs if r['is_mentioned'])
        p_cot = sum(1 for r in p_recs if r.get('mentioned_in_reasoning') and not r['is_mentioned'])
        p_rate = (p_ment / p_total * 100)
        
        print(f"    - æåŠç‡: {p_rate:.1f}% ({p_ment}/{p_total})")
        if p_cot > 0:
            print(f"    - æ¨ç†ä¸­æåŠä½†è¢«è¿‡æ»¤: {p_cot} æ¬¡")
        print("-" * 30)
        
        # 1. Competitor Analysis for this platform
        p_competitors = []
        for r in p_recs:
            if 'competitors' in r and isinstance(r['competitors'], list): p_competitors.extend(r['competitors'])
        
        print("  ğŸ”¥ ç«å“/å…³è”å…¬å¸æ’è¡Œ:")
        if p_competitors:
            for name, count in Counter(p_competitors).most_common(5):
                print(f"     - {name}: {count}")
        else:
            print("     (æ— æ•°æ®)")
            
        # 2. Source Analysis for this platform
        p_sources = []
        for r in p_recs:
            if 'sources_v2' in r and isinstance(r['sources_v2'], list):
                p_sources.extend([s['media'] for s in r['sources_v2']])
            elif 'sources' in r and isinstance(r['sources'], list):
                p_sources.extend(r['sources'])
            
        print("\n  ğŸ“¢ å¼•ç”¨ä¿¡æº/åª’ä½“:")
        if p_sources:
            for name, count in Counter(p_sources).most_common(5):
                print(f"     - {name}: {count}")
        else:
            print("     (æ— æ•°æ®)")
    
    print("-" * 60)
    
    # Global Source Recommendation
    print("\nğŸŒŸ ä¼˜è´¨ä¿¡æºæ¨è (åŸºäºå…¨å¹³å°å¼•ç”¨æƒé‡)")
    all_sources = []
    for r in all_records:
        if 'sources_v2' in r and isinstance(r['sources_v2'], list):
            all_sources.extend([s['media'] for s in r['sources_v2']])
        elif 'sources' in r and isinstance(r['sources'], list):
            all_sources.extend(r['sources'])
    
    if all_sources:
        top_sources = Counter(all_sources).most_common(5)
        print("å»ºè®®åœ¨ä»¥ä¸‹é«˜æƒé‡åª’ä½“å¢åŠ å†…å®¹æŠ•æ”¾ï¼š")
        for name, count in top_sources:
            print(f"  ğŸ‘‰ {name} (è¢«å¼•ç”¨ {count} æ¬¡)")
    else:
        print("  (æ•°æ®ä¸è¶³ï¼Œæš‚æ— æ¨è)")
        
    print("="*60 + "\n")

def run_auto_monitor_task():
    config = load_config()
    providers = config.get('providers', {})
    intents = config['intents']
    
    print("\nğŸš€  å¯åŠ¨å…¨å¹³å°å…¨è‡ªåŠ¨ç›‘æµ‹æ¨¡å¼ (ä¸€é”®æ‰˜ç®¡ç‰ˆ)")
    print("æ”¯æŒå¹³å°: " + ", ".join([p for p, c in providers.items() if c['enabled']]))
    print("ç³»ç»Ÿå°†ä¾æ¬¡éå†æ‰€æœ‰å¹³å°å’Œæ„å›¾ï¼Œæ— éœ€ä»»ä½•äººå·¥å¹²é¢„ã€‚\n")
    
    # Check keys first
    active_providers = []
    for p_name, p_config in providers.items():
        if not p_config['enabled']: continue
        
        if not p_config.get('api_key'):
            print(f"\nğŸ”‘  è¯·è¾“å…¥ {p_name} API Key (å›è½¦è·³è¿‡):")
            key = input("Key: ").strip()
            if key:
                providers[p_name]['api_key'] = key
                p_config['api_key'] = key # Update local ref
                active_providers.append((p_name, p_config))
            else:
                print(f"âš ï¸  è·³è¿‡ {p_name} (æ—  Key)")
        else:
            active_providers.append((p_name, p_config))
            
    if not active_providers:
        print("âŒ  æ²¡æœ‰å¯ç”¨çš„å¹³å°é…ç½®ã€‚è¯·è‡³å°‘é…ç½®ä¸€ä¸ª API Keyã€‚")
        save_config(config) # Save any keys entered
        return
        
    save_config(config) # Save keys
    
    # 1. First, use Deepseek (or the first available robust model) to generate all questions
    # We'll store them in a dictionary: {intent_label: [questions]}
    print("\n" + "="*50)
    print("ğŸ¨ æ­£åœ¨ç»Ÿä¸€ç”Ÿæˆç›‘æµ‹é—®é¢˜é›† (ä½¿ç”¨ Deepseek ä¿è¯è´¨é‡)")
    print("="*50)
    
    # Find a generator (prefer Deepseek)
    generator_name = "Deepseek" if "Deepseek" in [p[0] for p in active_providers] else active_providers[0][0]
    generator_config = next(p[1] for p in active_providers if p[0] == generator_name)
    generator_client = GenericClient(generator_name, generator_config)
    
    intent_questions = {}
    for intent in intents:
        print(f"   â³ æ­£åœ¨ä¸ºã€{intent['label']}ã€‘ç”Ÿæˆé—®é¢˜...")
        qs = generator_client.generate_questions(intent['label'], intent['keywords'], count=30)
        if qs:
            intent_questions[intent['label']] = qs
            print(f"      âœ… å·²ç”Ÿæˆ {len(qs)} ä¸ªé—®é¢˜")
        else:
            print(f"      âš ï¸ ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤é—®é¢˜ã€‚")
            intent_questions[intent['label']] = intent.get('questions', [])[:30]

    # 2. Main Loop - Ask each platform the same set of questions
    for p_name, p_config in active_providers:
        print(f"\n" + "="*50)
        print(f"ğŸ“± æ­£åœ¨ç›‘æµ‹å¹³å°: {p_name}")
        print("="*50)
        
        client = GenericClient(p_name, p_config)
        
        for intent_label, questions in intent_questions.items():
            print(f"\nğŸ“‚ æ„å›¾: {intent_label}")
            
            for idx, q in enumerate(questions):
                print(f"   â¡ï¸ æé—® ({idx+1}/{len(questions)}): {q}")
                
                # Simple retry logic
                result = None
                for _ in range(3):
                    result = client.chat([{"role": "user", "content": q}])
                    if result:
                        break
                    time.sleep(2)
                
                if not result:
                    print("   âŒ  æé—®å¤±è´¥ï¼Œè·³è¿‡ã€‚")
                    continue
                    
                timestamp = datetime.datetime.now().isoformat()
                mentioned, mentioned_in_cot = save_result(intent_label, p_name, q, result, timestamp)
                
                if mentioned:
                    print("      âœ…  å‘ç°æåŠï¼")
                elif mentioned_in_cot:
                     print("      ğŸ¤”  ä»…åœ¨æ¨ç†æ€è€ƒä¸­æåŠ (æœªè¾“å‡ºåˆ°ç»“æœ)")
                else:
                    print("      âŒ  æœªæåŠ")
                
                time.sleep(0.5)
            
    print("\nğŸ‰ æ‰€æœ‰å¹³å°ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ï¼æ­£åœ¨ç”Ÿæˆæ·±åº¦åˆ†ææŠ¥å‘Š...\n")
    generate_report()

def update_api_keys():
    config = load_config()
    providers = config.get('providers', {})
    
    print("\nğŸ”‘  ä¿®æ”¹ API Key")
    active_list = list(providers.keys())
    for idx, p_name in enumerate(active_list):
        has_key = " (å·²è®¾ç½®)" if providers[p_name].get('api_key') else " (æœªè®¾ç½®)"
        print(f"{idx + 1}. {p_name}{has_key}")
    print(f"{len(active_list) + 1}. è¿”å›ä¸»èœå•")
    
    try:
        choice = int(input("\nè¯·é€‰æ‹©è¦ä¿®æ”¹çš„å¹³å°æ•°å­—: ")) - 1
        if choice == len(active_list):
            return
        
        target_p = active_list[choice]
        new_key = input(f"è¯·è¾“å…¥ {target_p} çš„æ–° API Key: ").strip()
        if new_key:
            providers[target_p]['api_key'] = new_key
            save_config(config)
            print(f"âœ… {target_p} API Key å·²æ›´æ–°ï¼")
        else:
            print("âš ï¸  æœªè¾“å…¥å†…å®¹ï¼Œå–æ¶ˆä¿®æ”¹ã€‚")
    except:
        print("âŒ è¾“å…¥æ— æ•ˆã€‚")

def run_monitor_task():
    config = load_config()
    targets = config['targets']
    intents = config['intents']
    
    print("\nğŸš€  å¯åŠ¨ GEO ç›‘æµ‹ä»»åŠ¡")
    print("è¯·é€‰æ‹©è¦ç›‘æµ‹çš„å¹³å°:")
    for idx, t in enumerate(targets):
        print(f"{idx + 1}. {t}")
    
    try:
        t_choice = int(input("è¯·è¾“å…¥æ•°å­— (ä¾‹å¦‚ 1): ")) - 1
        target_platform = targets[t_choice]
    except:
        print("è¾“å…¥æ— æ•ˆï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªã€‚")
        target_platform = targets[0]

    print(f"\nå½“å‰ç›‘æµ‹å¹³å°: ã€{target_platform}ã€‘")
    print("æ¥ä¸‹æ¥ï¼Œç³»ç»Ÿå°†ä¾æ¬¡å±•ç¤ºé—®é¢˜ã€‚è¯·æ‚¨å°†é—®é¢˜å¤åˆ¶åˆ°å¤§æ¨¡å‹ä¸­æé—®ï¼Œç„¶åå°†å›ç­”ç²˜è´´å›æ¥ã€‚\n")
    
    for intent in intents:
        print(f"\nğŸ“‚  æ­£åœ¨ç›‘æµ‹æ„å›¾: {intent['label']}")
        for q in intent['questions']:
            print("\n" + "-"*30)
            print(f"â“  é—®é¢˜: {q}")
            print("-"*30)
            print("ğŸ‘‰  è¯·å¤åˆ¶ä¸Šé¢çš„é—®é¢˜å»æé—®ï¼Œç„¶åæŠŠå›ç­”ç²˜è´´åœ¨ä¸‹é¢ (æŒ‰ Enter ä¸¤æ¬¡ç»“æŸè¾“å…¥):")
            
            lines = []
            while True:
                line = input()
                if line == "":
                    break
                lines.append(line)
            answer = "\n".join(lines)
            
            if not answer.strip():
                print("âš ï¸  è·³è¿‡æ­¤é—®é¢˜ (æœªè¾“å…¥å›ç­”)")
                continue
                
            timestamp = datetime.datetime.now().isoformat()
            mentioned = save_result(intent['label'], target_platform, q, answer, timestamp)
            
            if mentioned:
                print("âœ…  ç›‘æµ‹åˆ°æåŠï¼")
            else:
                print("âŒ  æœªæåŠã€‚")

def main():
    print("\næ­£åœ¨åˆå§‹åŒ–ç³»ç»Ÿï¼Œè¯·ç¨å€™...", flush=True)
    while True:
        print("\n" + "#"*40)
        print("   è”æƒ³é›†å›¢ GEO ä¼˜åŒ–ç³»ç»Ÿ (OpenClaw Lite)")
        print("#"*40)
        print("1. âš¡ï¸  ä¸€é”®å¯åŠ¨å…¨å¹³å°å…¨è‡ªåŠ¨ç›‘æµ‹ (Deepseek/Kimi/Doubao/Yuanbao)")
        print("2. â–¶ï¸   æ‰‹åŠ¨è¾…åŠ©ç›‘æµ‹ (äººå·¥è¾“å…¥æ¨¡å¼)")
        print("3. ğŸ“Š  æŸ¥çœ‹åˆ†ææŠ¥å‘Š")
        print("4. ğŸ§   æ·±åº¦æ´å¯Ÿåˆ†æ (v2.3 æ–°åŠŸèƒ½)")
        print("5. ğŸ”  ç½‘ç»œç¯å¢ƒè¯Šæ–­")
        print("6. ğŸ”‘  ä¿®æ”¹/è®¾ç½® API Key")
        print("7. âŒ  é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©åŠŸèƒ½ (1-7): ")
        
        if choice == '1':
            run_auto_monitor_task()
        elif choice == '2':
            run_monitor_task()
        elif choice == '3':
            generate_report()
        elif choice == '4':
            engine = DeepInsightEngine()
            engine.run()
        elif choice == '5':
            run_diagnostics()
        elif choice == '6':
            update_api_keys()
        elif choice == '7':
            print("å†è§ï¼")
            sys.exit(0)
        else:
            print("æ— æ•ˆè¾“å…¥ï¼Œè¯·é‡è¯•ã€‚")

if __name__ == "__main__":
    main()
